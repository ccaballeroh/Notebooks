{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificacion de texto - transformadores - multiclase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5da7bb3628894dd49ac4924c0593049f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdda0c1798574486945c47523eb283fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3701d44b4384b648376e3256ad7728d",
              "IPY_MODEL_992edcee6ba142d6b1a7a00211b5eba2"
            ]
          }
        },
        "cdda0c1798574486945c47523eb283fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3701d44b4384b648376e3256ad7728d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_796b56633489485d99d435928eacbc85",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_708e944228a4444793b76f949aa0dafc"
          }
        },
        "992edcee6ba142d6b1a7a00211b5eba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a136a5fc53af4440808aaa025f6d6830",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.55MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f660c2ea1c34691b5256f0189f9bc21"
          }
        },
        "796b56633489485d99d435928eacbc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "708e944228a4444793b76f949aa0dafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a136a5fc53af4440808aaa025f6d6830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f660c2ea1c34691b5256f0189f9bc21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c84a98f7efc4abd8d11ae8b20ed0bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5b3c948469845729b5b8f64af81164c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_02ba00ddff5c4d38bd39a713d5fc3440",
              "IPY_MODEL_c5f221dc7826425abd6da58901c632cc"
            ]
          }
        },
        "b5b3c948469845729b5b8f64af81164c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02ba00ddff5c4d38bd39a713d5fc3440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85d8b7606bf64845bb92b9b1f7be2d9b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecb43e098596484a97edd8227a67840a"
          }
        },
        "c5f221dc7826425abd6da58901c632cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a825ac09309047cdbc38f63967181a38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [04:49&lt;00:00, 1.53B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d139a1a8ba2496d89ee8145c011f1ae"
          }
        },
        "85d8b7606bf64845bb92b9b1f7be2d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecb43e098596484a97edd8227a67840a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a825ac09309047cdbc38f63967181a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d139a1a8ba2496d89ee8145c011f1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f8a2be6cd7a4215abf71d72a8d8a445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e08abb834cc4443b40f0420f6924a9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_177523bd693d410aba5acaa14a567000",
              "IPY_MODEL_b8dde9b47c35445195cde91fe0858b9b"
            ]
          }
        },
        "7e08abb834cc4443b40f0420f6924a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "177523bd693d410aba5acaa14a567000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad1fd32e0f3442e09610215ff3b04b07",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe4c05924f854be1882de28221ebb244"
          }
        },
        "b8dde9b47c35445195cde91fe0858b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85e1537a2fc94b019e8b6644f0893ab4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:19&lt;00:00, 13.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da3623e51d1345db836843f5a6bdbb32"
          }
        },
        "ad1fd32e0f3442e09610215ff3b04b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe4c05924f854be1882de28221ebb244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85e1537a2fc94b019e8b6644f0893ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da3623e51d1345db836843f5a6bdbb32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccaballeroh/Notebooks/blob/master/Clasificacion_de_texto_transformadores_multiclase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59Z5jPafUleX",
        "colab_type": "text"
      },
      "source": [
        "# ¿¡Transformadores!?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLg4i7rLQvYA",
        "colab_type": "text"
      },
      "source": [
        "## Atención\n",
        "\n",
        "Motivado por los problemas de eficiencia computacional inherentes con las Redes Neuronales Recurrentes, en 2017 aparece la arquitectura de los Transformadores [1]. Con este modelo se logra paralelizar el proceso de entrenamiento capturando las secuencias con atención, al mismo tiempo que se codifica la posición de cada elemento en la secuencia.\n",
        "\n",
        "> Los Transformadores se basan completamente en los mecanismos de auto-atención sin utilizar una arquitectura recurrente alineada en secuencia.\n",
        "\n",
        "En lugar de calcular la atención una sola vez, los Transformadores utilizan un mecanismo de cabezas múltiples que ejecutan la auto-atención varias veces en **paralelo**, permitiendo que el modelo atienda de forma conjunta a información de diferentes subespacios de representación en **diferentes posiciones**. Al final, las salidas de atención se concatenan y se transforman linealmente en las dimensiones esperadas. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://d2l.ai/_images/multi-head-attention.svg\" alt=\"Figure 10.3.3: https://d2l.ai/chapter_attention-mechanisms/transformer.html\" width=\"50%\">\n",
        "<br>\n",
        "<a href=\"https://d2l.ai/chapter_attention-mechanisms/transformer.html\" target=\"_top\">Multi-head attention</a> [2].\n",
        "<br>\n",
        "</center>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoSco0CWKey",
        "colab_type": "text"
      },
      "source": [
        "## Codificador\n",
        "\n",
        "El codificador genera una representación basada en la atención, con la capacidad de localizar información específica del contexto [1].\n",
        "\n",
        "<center>\n",
        "<img src=\"http://www.cs.virginia.edu/~pc9za/riiaa_2020/5.1.PNG\" alt=\"pesos\" width=\"15%\">\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "Contiene una pila de 6 capas idénticas (N). Cada capa tiene una capa de auto-atención de múltiples cabezas y cada subcapa tiene una conexión residual + capa de normalización. Todas las subcapas generan datos de la misma dimensión (512)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDHfsG19WM8N",
        "colab_type": "text"
      },
      "source": [
        "## Decodificador\n",
        "\n",
        "El decodificador se encarga de recobrar la representación codificada [1].\n",
        "\n",
        "<center>\n",
        "<img src=\"http://www.cs.virginia.edu/~pc9za/riiaa_2020/5.2.PNG\" alt=\"pesos\" width=\"15%\">\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "De igual manera, contiene una pila de 6 capas idénticas (N). Cada capa tiene dos subcapas de mecanismos de atención de múltiples cabezales y cada subcapa tiene una conexión residual + una capa de normalización.\n",
        "Es importante destacar que en el decodificador, la primera subcapa de atención se modifica para evitar que las posiciones atiendan a posiciones posteriores (evitar ver al futuro)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQA6tjeqU6Er",
        "colab_type": "text"
      },
      "source": [
        "# ¡Ajustemos un Transformador para clasificación de texto!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te83YYzbb6aN",
        "colab_type": "text"
      },
      "source": [
        "Vamos a trabajar con un [set de datos de noticias](https://archive.ics.uci.edu/ml/datasets/News+Aggregator) [3], las cuales vamos a clasificar en varias categorías. Trabajaremos con una version más pequeña del set original. Acá podrá descargar la versión modificada: [news_corpora_small.csv](http://www.cs.virginia.edu/~pc9za/riiaa_2020/news_corpora_small.csv)\n",
        "\n",
        "Ajustaremos un modelo de la familia de los Transformadores para clasificar los titulares de noticias en 4 categorías."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI2x4s9G_eiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4cdc7a3-ec0e-4768-82e7-a29bbb16dd21"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.cs.virginia.edu/~pc9za/riiaa_2020/news_corpora_small.csv', 'news_corpora_small.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('news_corpora_small.csv', <http.client.HTTPMessage at 0x7f627837b1d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDgIefZJf8ys",
        "colab_type": "text"
      },
      "source": [
        "## Instalemos Hugging Face\n",
        "![face](https://huggingface.co/front/assets/huggingface_logo.svg)\n",
        "\n",
        "Utilizaremos la librería de [Hugging Face](https://huggingface.co/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7W9SVA4VXgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "b6a50449-f508-4da8-983f-f1a2cbb9f0e7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=5c80c8bd9842b50378e7aac4f43937064fbd9549cbd1235f5ba8e4aac729a284\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aac404vkh9qr",
        "colab_type": "text"
      },
      "source": [
        "## El modelo :: Bidirectional Encoder Representations from Transformers\n",
        "\n",
        "Con Bidirectional Encoder Representations from Transformers (**BERT**), un modelo es pre-entrenado con datos que no requieren ser etiquetados. Una vez entrenado, el modelo genera una representación densa de la entrada. Para resolver otras tareas de PLN, como *clasificación de texto*, modificamos el modelo (e.g. agregando mas capas) y lo volvemos a entrenar con los datos (en este caso los titulares de las noticias) y sus respectivas etiquetas (nuestras 4 categorías).\n",
        "\n",
        "Trabajaremos con una versión más pequeña de BERT: [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) [4]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ycGrSGbQsMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importamos torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# importamos la libreria de hugging face\n",
        "import transformers\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "# importamos pandas\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irGD3UrZkbgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos el csv en pandas\n",
        "df = pd.read_csv('news_corpora_small.csv', sep=',', names=['ID','TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "# trabajaremos unicamente con los encabezados y las categorias\n",
        "df = df[['TITLE','CATEGORY']]\n",
        "\n",
        "# setear ids y descripciones de categorias\n",
        "cat_to_id = {\n",
        "    'e':0,\n",
        "    'b':1,\n",
        "    't':2,\n",
        "    'm':3\n",
        "}\n",
        "letter_to_desc = {\n",
        "    'e':'Entretenimiento',\n",
        "    'b':'Beneficios',\n",
        "    't':'Tecnologia',\n",
        "    'm':'Medicina'\n",
        "}\n",
        "def add_cat_id(x):\n",
        "    return cat_to_id[x]\n",
        "df['ENCODE_CAT'] = df['CATEGORY'].apply(lambda x: add_cat_id(x))\n",
        "\n",
        "def update_cat(x):\n",
        "    return letter_to_desc[x]\n",
        "df['CATEGORY'] = df['CATEGORY'].apply(lambda x: update_cat(x))\n",
        "\n",
        "id_to_desc = {\n",
        "    0:'Entretenimiento',\n",
        "    1:'Beneficios',\n",
        "    2:'Tecnologia',\n",
        "    3:'Medicina'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "242nPkIMnn6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "7624b5f5-d3fc-43f8-c994-9638311952b3"
      },
      "source": [
        "print (\"Tamano del set de datos: {}\".format(len(df)))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamano del set de datos: 40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>ENCODE_CAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Breaking Bad's Bryan Cranston helps student ge...</td>\n",
              "      <td>Entretenimiento</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is AC/DC retiring?</td>\n",
              "      <td>Entretenimiento</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Horrible Bosses 2' Trailer Shows A Desperate ...</td>\n",
              "      <td>Entretenimiento</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lupita Nyong'o named 'Most Beautiful' woman by...</td>\n",
              "      <td>Entretenimiento</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6 TV Shows We'd Like To See Get The Big-Screen...</td>\n",
              "      <td>Entretenimiento</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TITLE  ... ENCODE_CAT\n",
              "0  Breaking Bad's Bryan Cranston helps student ge...  ...          0\n",
              "1                                 Is AC/DC retiring?  ...          0\n",
              "2  'Horrible Bosses 2' Trailer Shows A Desperate ...  ...          0\n",
              "3  Lupita Nyong'o named 'Most Beautiful' woman by...  ...          0\n",
              "4  6 TV Shows We'd Like To See Get The Big-Screen...  ...          0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VURNZcBhoHlj",
        "colab_type": "text"
      },
      "source": [
        "Dividimos el set de datos en dos subsets: uno de entrenamiento (75% de los datos) y otro de prueba (25% de los datos).\n",
        "\n",
        "Definimos nuestro Dataset y Dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oed_gMOoBPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class News_Headears(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=60):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.length = len(data)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        inputs = self.tokenizer.encode_plus(self.data.TITLE[index],\n",
        "                                            None,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_length,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True,\n",
        "                                            truncation=True)\n",
        "        return torch.tensor(inputs['input_ids'], dtype=torch.long), torch.tensor(inputs['attention_mask'], dtype=torch.long), torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m8X2-ygogGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "5da7bb3628894dd49ac4924c0593049f",
            "cdda0c1798574486945c47523eb283fa",
            "f3701d44b4384b648376e3256ad7728d",
            "992edcee6ba142d6b1a7a00211b5eba2",
            "796b56633489485d99d435928eacbc85",
            "708e944228a4444793b76f949aa0dafc",
            "a136a5fc53af4440808aaa025f6d6830",
            "7f660c2ea1c34691b5256f0189f9bc21"
          ]
        },
        "outputId": "79c10810-d39f-41f2-e08d-7f5f41bed223"
      },
      "source": [
        "# Definimos nuestro split\n",
        "TRAIN_SPLIT_SIZE = 0.75\n",
        "BATCH_SIZE = 16\n",
        "train_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 12 }\n",
        "test_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 12 }\n",
        "\n",
        "train_dataset = df.sample(frac=TRAIN_SPLIT_SIZE, random_state=0) # seteamos una semilla para obtener la misma particion posteriormente\n",
        "test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"Dataset de entrenamiento: {}\".format(train_dataset.shape))\n",
        "print(\"Dataset de prueba: {}\".format(test_dataset.shape))\n",
        "\n",
        "print (\"\\nNumero de datos correspondientes a cada categoria en nuestro split de entrenamiento:\")\n",
        "print (train_dataset['CATEGORY'].value_counts())\n",
        "print (\"\\nNumero de datos correspondientes a cada categoria en nuestro split de prueba:\")\n",
        "print (test_dataset['CATEGORY'].value_counts())\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
        "train_data = News_Headears(train_dataset, tokenizer)\n",
        "test_data = News_Headears(test_dataset, tokenizer)\n",
        "\n",
        "training_loader = DataLoader(train_data, **train_params)\n",
        "testing_loader = DataLoader(test_data, **test_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset de entrenamiento: (30000, 3)\n",
            "Dataset de prueba: (10000, 3)\n",
            "\n",
            "Numero de datos correspondientes a cada categoria en nuestro split de entrenamiento:\n",
            "Tecnologia         7543\n",
            "Entretenimiento    7512\n",
            "Beneficios         7493\n",
            "Medicina           7452\n",
            "Name: CATEGORY, dtype: int64\n",
            "\n",
            "Numero de datos correspondientes a cada categoria en nuestro split de prueba:\n",
            "Medicina           2548\n",
            "Beneficios         2507\n",
            "Entretenimiento    2488\n",
            "Tecnologia         2457\n",
            "Name: CATEGORY, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5da7bb3628894dd49ac4924c0593049f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiAC1v5StEu5",
        "colab_type": "text"
      },
      "source": [
        "Ahora vamos a definir la arquitectura del modelo que vamos a utilizar para entrenar nuestra tarea de clasificacion.\n",
        "\n",
        "Concatenaremos una capa lineal a DistillBERT y ajustaremos nuestro modelo.\n",
        "\n",
        "BERT agrega una token llamado *CLS* al comienzo de cada oración para clasificación. Ese token se puede considerar como un embedding de toda la oración (por eso tomamos <code>output[0][:,0,:]</code> como entrada a nuestra capa lineal de clasificacion)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXuAwfzSt9ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.bert_output = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.ll1 = torch.nn.Linear(768, 50)\n",
        "        self.ll2 = torch.nn.Linear(50, 4)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "        output = self.bert_output(ids, mask)\n",
        "        output = torch.relu(self.ll1(output[0][:,0,:]))\n",
        "        output = self.ll2(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLgbhiEZuWVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c84a98f7efc4abd8d11ae8b20ed0bac",
            "b5b3c948469845729b5b8f64af81164c",
            "02ba00ddff5c4d38bd39a713d5fc3440",
            "c5f221dc7826425abd6da58901c632cc",
            "85d8b7606bf64845bb92b9b1f7be2d9b",
            "ecb43e098596484a97edd8227a67840a",
            "a825ac09309047cdbc38f63967181a38",
            "4d139a1a8ba2496d89ee8145c011f1ae",
            "9f8a2be6cd7a4215abf71d72a8d8a445",
            "7e08abb834cc4443b40f0420f6924a9d",
            "177523bd693d410aba5acaa14a567000",
            "b8dde9b47c35445195cde91fe0858b9b",
            "ad1fd32e0f3442e09610215ff3b04b07",
            "fe4c05924f854be1882de28221ebb244",
            "85e1537a2fc94b019e8b6644f0893ab4",
            "da3623e51d1345db836843f5a6bdbb32"
          ]
        },
        "outputId": "e32657e1-78b9-494e-a3aa-f545ca9fdf20"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print (\"Si tenemos un GPU disponible, usemoslo! - Device: {}\\n\".format(device))\n",
        "\n",
        "model = Model()\n",
        "model.to(device)\n",
        "print (model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Si tenemos un GPU disponible, usemoslo! - Device: cuda\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c84a98f7efc4abd8d11ae8b20ed0bac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f8a2be6cd7a4215abf71d72a8d8a445",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model(\n",
            "  (bert_output): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ll1): Linear(in_features=768, out_features=50, bias=True)\n",
            "  (ll2): Linear(in_features=50, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaOMoEPQu4Lt",
        "colab_type": "text"
      },
      "source": [
        "## Ajustemos el modelo\n",
        "\n",
        "Utilizaremos CE como funcion de perdida y Adam como algoritmo optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W0mYlvivGPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhK3LamNvtiA",
        "colab_type": "text"
      },
      "source": [
        "Definamos nuestra funcion de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj3E4vogvwOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for i, (ids, mask, targets) in enumerate(training_loader):\n",
        "        ids = ids.to(device)\n",
        "        mask = mask.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(outputs, targets)\n",
        "        if i%100 == 0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qEZYkHbwOIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "85022dd1-6142-456f-e2cf-0c2c7ce51426"
      },
      "source": [
        "EPOCHS = 2\n",
        "for epoch in range(0, EPOCHS):\n",
        "  train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  1.365579605102539\n",
            "Epoch: 0, Loss:  1.3933652639389038\n",
            "Epoch: 0, Loss:  1.3278939723968506\n",
            "Epoch: 0, Loss:  1.3729243278503418\n",
            "Epoch: 0, Loss:  1.2607274055480957\n",
            "Epoch: 0, Loss:  0.952964723110199\n",
            "Epoch: 0, Loss:  1.0547508001327515\n",
            "Epoch: 0, Loss:  1.2827869653701782\n",
            "Epoch: 0, Loss:  1.0623592138290405\n",
            "Epoch: 0, Loss:  0.9535151124000549\n",
            "Epoch: 0, Loss:  0.7681649923324585\n",
            "Epoch: 0, Loss:  0.8218606114387512\n",
            "Epoch: 0, Loss:  0.6384872198104858\n",
            "Epoch: 0, Loss:  0.559400737285614\n",
            "Epoch: 0, Loss:  0.4348406195640564\n",
            "Epoch: 0, Loss:  0.9387041330337524\n",
            "Epoch: 0, Loss:  0.295390784740448\n",
            "Epoch: 0, Loss:  0.39555802941322327\n",
            "Epoch: 0, Loss:  0.2449529618024826\n",
            "Epoch: 1, Loss:  0.5813267230987549\n",
            "Epoch: 1, Loss:  0.5266097784042358\n",
            "Epoch: 1, Loss:  0.44435983896255493\n",
            "Epoch: 1, Loss:  0.46799609065055847\n",
            "Epoch: 1, Loss:  0.437944620847702\n",
            "Epoch: 1, Loss:  0.6578884124755859\n",
            "Epoch: 1, Loss:  0.7687342762947083\n",
            "Epoch: 1, Loss:  0.6048207879066467\n",
            "Epoch: 1, Loss:  0.5110716223716736\n",
            "Epoch: 1, Loss:  0.3256896138191223\n",
            "Epoch: 1, Loss:  0.8068650960922241\n",
            "Epoch: 1, Loss:  0.4653782844543457\n",
            "Epoch: 1, Loss:  0.5814889669418335\n",
            "Epoch: 1, Loss:  0.4076480567455292\n",
            "Epoch: 1, Loss:  0.7971840500831604\n",
            "Epoch: 1, Loss:  0.47864893078804016\n",
            "Epoch: 1, Loss:  0.2145335078239441\n",
            "Epoch: 1, Loss:  0.39820221066474915\n",
            "Epoch: 1, Loss:  0.5398969650268555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFFsYLB3NZ8",
        "colab_type": "text"
      },
      "source": [
        "## Validemos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS4mnP9h3UNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df637322-965b-4f0d-ebf7-8681bdb0dd38"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "n_correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for (ids, mask, targets) in testing_loader:\n",
        "        ids = ids.to(device)\n",
        "        mask = mask.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        softmax_outputs = F.softmax(outputs, dim=1)\n",
        "        big_val, big_idx = torch.max(softmax_outputs.data, dim=1)\n",
        "        \n",
        "        total += len(targets)\n",
        "        n_correct += (big_idx==targets).sum().item()\n",
        "\n",
        "print (\"Con tan solo {} epochs de entrenamiento, el accuracy de nuestro modelo es de: {}%\".format(EPOCHS, (n_correct*100.0)/total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Con tan solo 2 epochs de entrenamiento, el accuracy de nuestro modelo es de: 82.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcgpA9Xb9oBd",
        "colab_type": "text"
      },
      "source": [
        "Salvemos los parametros y pesos de nuestro para resumir el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0vIhYwe5LH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2892e038-ec9a-473b-db46-a28b423aebfa"
      },
      "source": [
        "model_checkpoint = '{}_epochs_model.ckpt'.format(EPOCHS)\n",
        "vocab_file = 'vocab.ckpt'\n",
        "\n",
        "torch.save(model, model_checkpoint)\n",
        "tokenizer.save_vocabulary(vocab_file)\n",
        "\n",
        "print (\"Modelo y vocabulario guardados\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo y vocabulario guardados\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4vDou83Svff",
        "colab_type": "text"
      },
      "source": [
        "Ahora probemos nuestro modelo con algun input real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDSgK7T5S6Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Ingrese una oración para clasificarla en una de los cuatro categorias definidas. { display-mode: \"form\" }\n",
        "\n",
        "input = 'Protect Your Privacy and the Environment While Upgrading Your Gear' #@param {type:\"string\"}\n",
        "\n",
        "tokenized_input = tokenizer.encode_plus(input,\n",
        "                                None,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=60,\n",
        "                                pad_to_max_length=True,\n",
        "                                return_token_type_ids=True,\n",
        "                                truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFBfmRZYTzz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85af8830-a840-4b94-d8ce-72a491562b7a"
      },
      "source": [
        "outputs = model(torch.tensor(tokenized_input['input_ids'], dtype=torch.long).unsqueeze(0).cuda(), torch.tensor(tokenized_input['attention_mask'], dtype=torch.long).unsqueeze(0).cuda())\n",
        "softmax_outputs = F.softmax(outputs, dim=1)\n",
        "out_val, out_idx = torch.max(softmax_outputs.data, dim=1)\n",
        "print (\"Entrada: \\\"{}\\\" || Categoría: {}\".format(input, id_to_desc[out_idx.item()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada: \"Protect Your Privacy and the Environment While Upgrading Your Gear\" || Categoría: Tecnologia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9nvvReB9xV_",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "\n",
        "\n",
        "1.   Modifique el modelo para obtener un mejor accuracy\n",
        "2.   Cambie los hiper-parametros, por ejemplo: cambiar el learning rate, o el algoritmo de optimizacion (utilizar SGD en lugar de Adam)\n",
        "3.   Dibuje las curvas de el loss y el accuracy durante el entrenamiento - utilizando el training set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtRO_qM7U49X",
        "colab_type": "text"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "[1] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. \"Attention is all you need.\" In Advances in neural information processing systems, pp. 5998-6008. 2017.\n",
        "\n",
        "[2] D2l.ai. 2020. 10.3. Transformer — Dive Into Deep Learning 0.14.3 Documentation. [online] Disponible en: <https://d2l.ai/chapter_attention-mechanisms/transformer.html>. Accesado el 20 Agosto del 2020.\n",
        "\n",
        "[3] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
        "\n",
        "[4] Sanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108."
      ]
    }
  ]
}